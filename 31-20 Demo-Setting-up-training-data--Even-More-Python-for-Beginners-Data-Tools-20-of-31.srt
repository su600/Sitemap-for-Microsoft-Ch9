1
00:00:00,000 --> 00:00:04,860
>> Let's take a look at a
code example of how we can

2
00:00:04,860 --> 00:00:09,510
split up our data into training
data and testing data,

3
00:00:09,510 --> 00:00:11,040
So just like before,

4
00:00:11,040 --> 00:00:12,480
we're going to need pandas,

5
00:00:12,480 --> 00:00:15,030
So let me import that in,

6
00:00:15,030 --> 00:00:20,130
Let's import in a CSV file
and check out its shape,

7
00:00:20,130 --> 00:00:25,320
What you're going to notice is
the fact that we have 30,000

8
00:00:25,320 --> 00:00:30,690
rows and 16 columns
inside of our data,

9
00:00:30,690 --> 00:00:35,390
Now we're going to keep things
a little bit simple here,

10
00:00:35,390 --> 00:00:39,140
that normally at this point after
you've loaded up your CSV file,

11
00:00:39,140 --> 00:00:41,540
you would probably
do some exploration,

12
00:00:41,540 --> 00:00:44,255
start to get rid of some bad data,

13
00:00:44,255 --> 00:00:47,330
maybe bring data in from
somewhere else, etc,

14
00:00:47,330 --> 00:00:49,745
Well, we're going
the green path here,

15
00:00:49,745 --> 00:00:52,595
where everything is just
going to work for us,

16
00:00:52,595 --> 00:00:57,185
So we're making our lives a
little bit easier, admittedly,

17
00:00:57,185 --> 00:01:01,320
But in the real world,

18
00:01:01,320 --> 00:01:02,880
there would still be
a little bit of work

19
00:01:02,880 --> 00:01:06,210
that you would have to do here,

20
00:01:06,210 --> 00:01:09,375
So 30,000 rows, 16 columns,

21
00:01:09,375 --> 00:01:12,800
Let's go ahead and start to break

22
00:01:12,800 --> 00:01:16,910
down all of that information
into the appropriate spots,

23
00:01:16,910 --> 00:01:22,930
So we're going to use the distance
and the elapsed time here,

24
00:01:22,930 --> 00:01:25,740
So you'll notice that we
called ahead just so we

25
00:01:25,740 --> 00:01:28,020
can see the first five rows here,

26
00:01:28,020 --> 00:01:30,090
All of that looks nice,

27
00:01:30,090 --> 00:01:34,690
and we're going to grab the delay,

28
00:01:34,690 --> 00:01:36,450
and that all looks good,

29
00:01:36,450 --> 00:01:39,195
So right now what we have,

30
00:01:39,195 --> 00:01:41,160
is we've got two new DataFrames,

31
00:01:41,160 --> 00:01:43,620
We've got x, which is our features,

32
00:01:43,620 --> 00:01:45,440
This is everything
that we're going to

33
00:01:45,440 --> 00:01:48,020
use to try and do our predictions,

34
00:01:48,020 --> 00:01:50,120
Then over on the y side,

35
00:01:50,120 --> 00:01:52,940
this is the value that we're
now trying to predict,

36
00:01:52,940 --> 00:01:56,585
So given the distance

37
00:01:56,585 --> 00:01:58,895
and the amount of time that
it took, how late is that?

38
00:01:58,895 --> 00:02:01,975
That's what we're
trying to set up here,

39
00:02:01,975 --> 00:02:06,740
Now, what we need to do in order
to be able to feed this into

40
00:02:06,740 --> 00:02:09,260
a model and start to train that up is

41
00:02:09,260 --> 00:02:12,105
we need some testing data
and some training data,

42
00:02:12,105 --> 00:02:14,570
Where again the testing data is going

43
00:02:14,570 --> 00:02:17,030
to be used to validate
all of the assumptions,

44
00:02:17,030 --> 00:02:22,440
the training data is going to
be used to build up that model,

45
00:02:22,440 --> 00:02:25,280
We're going to use that
nice little helper function

46
00:02:25,280 --> 00:02:27,470
here of train test split,

47
00:02:27,470 --> 00:02:32,120
Then we're going to set up
our x train and x test,

48
00:02:32,120 --> 00:02:34,645
y train and y test,

49
00:02:34,645 --> 00:02:37,595
and we're going to pass
it in the x and y,

50
00:02:37,595 --> 00:02:40,535
Again, our x is going
to be our features,

51
00:02:40,535 --> 00:02:43,490
our y is going to be what it is
that we're trying to predict,

52
00:02:43,490 --> 00:02:46,040
We're going to set up 30 percent as

53
00:02:46,040 --> 00:02:49,865
the test size and then
the random state of 42,

54
00:02:49,865 --> 00:02:52,340
So now when I run this,

55
00:02:52,340 --> 00:02:56,300
and I take a look at the
shape for that x train,

56
00:02:56,300 --> 00:03:02,325
what we're going to notice is
21,000 rows inside of there,

57
00:03:02,325 --> 00:03:04,985
When we look at the test,

58
00:03:04,985 --> 00:03:10,790
what we're going to notice is
9,000 rows inside of there,

59
00:03:10,790 --> 00:03:13,830
So you'll notice that we now

60
00:03:13,830 --> 00:03:19,175
have 30 percent of our data that's
going to be set up as testing,

61
00:03:19,175 --> 00:03:20,960
and we're going to have 70 percent of

62
00:03:20,960 --> 00:03:23,905
our data that's set up as training,

63
00:03:23,905 --> 00:03:26,540
Now, if you're anything like me,

64
00:03:26,540 --> 00:03:28,100
and I know I am,

65
00:03:28,100 --> 00:03:30,110
you might be looking at
that real quick and going,

66
00:03:30,110 --> 00:03:31,910
"Hey, wait a minute, those
numbers don't seem in the lineup,

67
00:03:31,910 --> 00:03:33,675
You have 30,000 rows,

68
00:03:33,675 --> 00:03:35,055
shouldn't it be 20 and 10?"

69
00:03:35,055 --> 00:03:37,475
Remember, we didn't say a third,

70
00:03:37,475 --> 00:03:39,260
we said 30 percent,

71
00:03:39,260 --> 00:03:43,605
so 30 percent of 30,000 is 9,000,

72
00:03:43,605 --> 00:03:46,050
Maybe it was just me
that got caught on that,

73
00:03:46,050 --> 00:03:47,400
maybe you're looking
at that and going,

74
00:03:47,400 --> 00:03:49,380
"Okay, yeah, that
makes complete sense,"

75
00:03:49,380 --> 00:03:51,555
Either way, there you are,

76
00:03:51,555 --> 00:03:55,860
So those are a couple of numbers,

77
00:03:55,860 --> 00:03:57,625
Then we'll also notice,

78
00:03:57,625 --> 00:04:01,490
if I go in and grab the
head of train, for example,

79
00:04:01,490 --> 00:04:03,965
that I did in fact get

80
00:04:03,965 --> 00:04:09,155
back completely random
rows on the train side,

81
00:04:09,155 --> 00:04:11,645
Then if I took a look at why,

82
00:04:11,645 --> 00:04:13,610
I'm going to see the
exact same thing,

83
00:04:13,610 --> 00:04:17,130
So there's our train and test,

84
00:04:17,130 --> 00:04:20,130
again, the shape on both of those,

85
00:04:20,130 --> 00:04:24,720
Then what you're going to
notice is on the head,

86
00:04:24,720 --> 00:04:27,840
we're getting our random IDs,

87
00:04:27,840 --> 00:04:31,315
But I do want to point
out this fact here,

88
00:04:31,315 --> 00:04:33,830
that you'll notice if I do this,

89
00:04:33,830 --> 00:04:39,210
I can actually go x train head,

90
00:04:39,230 --> 00:04:43,340
There we go, Let's go
ahead and run this is,

91
00:04:43,340 --> 00:04:45,470
and I'm going to just
draw on the screen,

92
00:04:45,470 --> 00:04:46,835
make it a little easier,

93
00:04:46,835 --> 00:04:49,565
Let me "Launch",
"Zoom" it real quick,

94
00:04:49,565 --> 00:04:52,655
There we go, So up
the very top there,

95
00:04:52,655 --> 00:04:55,590
this is my y,

96
00:04:57,440 --> 00:05:00,345
and then down below, that's our x,

97
00:05:00,345 --> 00:05:02,250
What I want you to notice here,

98
00:05:02,250 --> 00:05:07,335
is that the IDs line up,
and that's important,

99
00:05:07,335 --> 00:05:10,310
So then that way, because we've
split all of our data up,

100
00:05:10,310 --> 00:05:12,080
I've got my features over here,

101
00:05:12,080 --> 00:05:13,780
I've got my labels over here,

102
00:05:13,780 --> 00:05:15,575
What's going to drive the prediction?

103
00:05:15,575 --> 00:05:17,345
What it is that we're
trying to predict?

104
00:05:17,345 --> 00:05:19,820
I've now got that in two
separate DataFrames,

105
00:05:19,820 --> 00:05:23,780
We need to be able to at some
point bring all of those together,

106
00:05:23,780 --> 00:05:26,900
That's what that ID column
is going to do for us,

107
00:05:26,900 --> 00:05:30,695
and that's why all
of that matches up,

108
00:05:30,695 --> 00:05:33,890
Okay, now that we've got
the data ready to go,

109
00:05:33,890 --> 00:05:38,610
let's see how we could
begin to train up a model,


1
00:00:01,310 --> 00:00:03,690
>> So continuing with

2
00:00:03,690 --> 00:00:06,000
the fact that in a lot
of data science courses,

3
00:00:06,000 --> 00:00:07,035
and tutorials you look at,

4
00:00:07,035 --> 00:00:09,015
there's a lot of talk
about preparing data,

5
00:00:09,015 --> 00:00:11,580
One of the other scenarios that
you'll often have to handle,

6
00:00:11,580 --> 00:00:14,235
is handling duplicate rows,

7
00:00:14,235 --> 00:00:16,680
You'll see that data science really

8
00:00:16,680 --> 00:00:18,970
doesn't like it when there's
multiple copies of the same row,

9
00:00:18,970 --> 00:00:21,920
and they also tend to
get upset or crash,

10
00:00:21,920 --> 00:00:25,800
Even can crash code if encounter
rows which have missing values,

11
00:00:25,800 --> 00:00:28,080
So let's see how
Python and the pandas

12
00:00:28,080 --> 00:00:29,930
DataFrame gives us some methods

13
00:00:29,930 --> 00:00:32,910
and techniques for
handling those situations,

14
00:00:33,370 --> 00:00:36,695
Specifically, let's start
with the missing values,

15
00:00:36,695 --> 00:00:39,140
There are many different
data science methods you'll

16
00:00:39,140 --> 00:00:40,370
use which will actually

17
00:00:40,370 --> 00:00:42,535
crash if they hit a row
with missing values,

18
00:00:42,535 --> 00:00:44,720
So if I had the DataFrame
here in front of me

19
00:00:44,720 --> 00:00:46,820
for some airport
information because I have

20
00:00:46,820 --> 00:00:48,650
an arrival time and the
delay time that are

21
00:00:48,650 --> 00:00:51,110
missing values showing
up as that NaN,

22
00:00:51,110 --> 00:00:53,180
This could actually
cause my code to crash,

23
00:00:53,180 --> 00:00:55,105
I won't be able to train a model,

24
00:00:55,105 --> 00:00:57,560
So one of the things
we need is a way of

25
00:00:57,560 --> 00:01:01,145
knowing if a particular
DataFrame has missing values,

26
00:01:01,145 --> 00:01:04,925
The info method of the DataFrame
is fantastic for this,

27
00:01:04,925 --> 00:01:07,760
What it'll do, it'll tell you-all
sorts of great information,

28
00:01:07,760 --> 00:01:09,230
One of the things it'll tell you is

29
00:01:09,230 --> 00:01:11,255
how many rows are in your DataFrame,

30
00:01:11,255 --> 00:01:13,984
Then for each of the columns,

31
00:01:13,984 --> 00:01:16,070
it will tell you how
many of the rows in that

32
00:01:16,070 --> 00:01:19,745
DataFrame contain values
that are not null,

33
00:01:19,745 --> 00:01:22,625
So you can see here that
the flight date, well,

34
00:01:22,625 --> 00:01:26,420
all 300,000 rows contain
non null values,

35
00:01:26,420 --> 00:01:28,910
So there are actual values
at every single row for

36
00:01:28,910 --> 00:01:31,540
the value of flight date
and for unique carrier,

37
00:01:31,540 --> 00:01:35,780
But wait, when I hit "Tail
Number," out of that 300,000 rows,

38
00:01:35,780 --> 00:01:40,175
only 299,000 or so of
them have actual values,

39
00:01:40,175 --> 00:01:41,910
non null values in them,

40
00:01:41,910 --> 00:01:44,330
That means that some of those rows

41
00:01:44,330 --> 00:01:47,330
do contain a null or a missing value,

42
00:01:47,330 --> 00:01:50,510
So you can see here there's
actually three different columns

43
00:01:50,510 --> 00:01:54,230
that have a number lower
than 300,000 with non null,

44
00:01:54,230 --> 00:01:56,015
So that indicates to me there are

45
00:01:56,015 --> 00:01:59,875
some missing values for some of
the rows of this three columns,

46
00:01:59,875 --> 00:02:02,555
So now that I know I have
some missing values,

47
00:02:02,555 --> 00:02:05,905
how can I now use Python
to deal with those values?

48
00:02:05,905 --> 00:02:09,860
Well, fortunately, Python
pandas is designed for this,

49
00:02:09,860 --> 00:02:11,915
so it has a dropna method,

50
00:02:11,915 --> 00:02:14,840
which means dropna those NaN values,

51
00:02:14,840 --> 00:02:18,250
and it allows me to remove
those rows from my DataFrame,

52
00:02:18,250 --> 00:02:20,525
Now one thing to be aware of,

53
00:02:20,525 --> 00:02:22,955
very specific when working
the pandas DataFrames,

54
00:02:22,955 --> 00:02:25,100
When I do a dropna, I have not

55
00:02:25,100 --> 00:02:27,875
actually dropping the rows
from the DataFrame itself,

56
00:02:27,875 --> 00:02:31,130
I am saying drop the
rows and then copy

57
00:02:31,130 --> 00:02:35,000
the DataFrame with the dropped
rows to a new DataFrame,

58
00:02:35,000 --> 00:02:37,550
So here I have this
one row with values,

59
00:02:37,550 --> 00:02:40,190
what it does is it creates
new DataFrame called

60
00:02:40,190 --> 00:02:43,790
delay no nulls DataFrame and
it's missing that row 2,

61
00:02:43,790 --> 00:02:46,615
which had the null values
or the missing values,

62
00:02:46,615 --> 00:02:50,870
If however you want to actually
modify the DataFrame itself,

63
00:02:50,870 --> 00:02:52,880
you can do that by just specifying

64
00:02:52,880 --> 00:02:55,340
inplace equals true and
then what happens is

65
00:02:55,340 --> 00:02:57,425
literally just remove that row

66
00:02:57,425 --> 00:03:01,080
from the existing
delays df DataFrame,

67
00:03:02,090 --> 00:03:06,145
The other scenario we might need
to handle is duplicate rows,

68
00:03:06,145 --> 00:03:07,810
So you will often find that

69
00:03:07,810 --> 00:03:09,715
a lot of times we're
working with data science,

70
00:03:09,715 --> 00:03:12,340
you'll be given files from
multiple different places then

71
00:03:12,340 --> 00:03:15,370
you combine all those files
together into one DataFrame,

72
00:03:15,370 --> 00:03:18,370
That may mean that you
get into situations where

73
00:03:18,370 --> 00:03:21,240
sometimes rows may be
loaded multiple times,

74
00:03:21,240 --> 00:03:23,590
We also want to handle
those duplicate rows

75
00:03:23,590 --> 00:03:26,905
because that can skew results
when you're doing data science,

76
00:03:26,905 --> 00:03:29,080
So here I have some
data in front of me

77
00:03:29,080 --> 00:03:31,375
and some simple information
about airports,

78
00:03:31,375 --> 00:03:35,395
but I have two rows for the
airport in Dulles, Washington,

79
00:03:35,395 --> 00:03:38,890
So how do I handle that
using my Python on my panda,

80
00:03:38,890 --> 00:03:41,150
and Python and Pandas?

81
00:03:41,150 --> 00:03:45,100
We have the airports
DataFrame we call duplicated,

82
00:03:45,100 --> 00:03:46,910
and what that will
do is it will return

83
00:03:46,910 --> 00:03:48,935
true or false for every row,

84
00:03:48,935 --> 00:03:51,560
If a raw locates is

85
00:03:51,560 --> 00:03:54,905
a duplicate of a previous
row, then we'll see a true,

86
00:03:54,905 --> 00:03:57,710
So you can see here that the
first row, it returns false,

87
00:03:57,710 --> 00:03:59,900
second row is false because up

88
00:03:59,900 --> 00:04:02,345
until now it has not seen
a duplicate of Dulles,

89
00:04:02,345 --> 00:04:04,760
The next row is another row,

90
00:04:04,760 --> 00:04:07,160
is exactly the same
so now it says true

91
00:04:07,160 --> 00:04:11,810
because this row is a duplicate
of a previously seen row,

92
00:04:11,810 --> 00:04:13,655
and the remaining
rows were all false,

93
00:04:13,655 --> 00:04:15,560
I also want to make
sure we highlight here,

94
00:04:15,560 --> 00:04:17,900
that it's the entire
row is a duplicate,

95
00:04:17,900 --> 00:04:20,720
We have multiple records
with a country of USA,

96
00:04:20,720 --> 00:04:22,760
but duplicate is looking for records

97
00:04:22,760 --> 00:04:25,375
with the entire row is a duplicate,

98
00:04:25,375 --> 00:04:28,270
So this allows us to
locate duplicate records,

99
00:04:28,270 --> 00:04:29,615
Now, how did we get rid of them?

100
00:04:29,615 --> 00:04:31,850
Well, there's a
wonderful little method

101
00:04:31,850 --> 00:04:33,980
called drop duplicates
and I'm going to

102
00:04:33,980 --> 00:04:35,420
use that same little trick I did

103
00:04:35,420 --> 00:04:38,150
for dropping missing
rows and missing values,

104
00:04:38,150 --> 00:04:40,310
I'm going to use the
inplace equals true to

105
00:04:40,310 --> 00:04:43,280
say within this DataFrame itself drop

106
00:04:43,280 --> 00:04:46,460
the duplicate rows and what
that's going to simply do for me

107
00:04:46,460 --> 00:04:49,715
is get rid of that second
row for Dulles, Washington,

108
00:04:49,715 --> 00:04:52,025
So my data is all set nice and tidy,

109
00:04:52,025 --> 00:04:54,020
ready for me to go on and
play with my data science,

110
00:04:54,020 --> 00:04:56,725
So now we've dropped
our duplicate rows,

111
00:04:56,725 --> 00:05:00,250
We're ready to start going and
doing things like training models,

112
00:05:00,250 --> 00:05:03,420
Now, let's try all of
us out in actual code,

